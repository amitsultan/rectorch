{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rectorch_basics_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yYIlIpBVFB7"
      },
      "source": [
        "# **rectorch**: basic concepts\n",
        "\n",
        "This tutorial will show examples of how to train and test a model. The tutorial will focus on baseline models but the concepts are almost the same in the case of more advanced models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIfa_IRJWIQV"
      },
      "source": [
        "## Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G-sq-6gVlKC"
      },
      "source": [
        "### Dataset download\n",
        "For the purposes of this tutorial we download the *movielens 1M* dataset. As the name suggests, this dataset contains roughly one million (5 stars) ratings about movies. For more details, please refer to the official web page https://grouplens.org/datasets/movielens/1m/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx-q130cT0QI",
        "outputId": "4f490f1d-81bf-442b-b475-79e249290eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "%cd /content/\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip\n",
        "!rm ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2020-09-14 14:17:53--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  13.8MB/s    in 0.4s    \n",
            "\n",
            "2020-09-14 14:17:54 (13.8 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0kfGGSYWKXU"
      },
      "source": [
        "### **rectorch** installation\n",
        "\n",
        "NOTE: in this version of the tutorial we load the *dev* version from [github](https://github.com/makgyver/rectorch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryMvRCKwT6mv",
        "outputId": "1a63bf14-949e-49be-dcbc-7f2cb7fb1873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "%cd /content/\n",
        "!git clone -b dev https://github.com/makgyver/rectorch.git\n",
        "%cd rectorch\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'rectorch'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 1705 (delta 17), reused 35 (delta 17), pack-reused 1650\u001b[K\n",
            "Receiving objects: 100% (1705/1705), 3.22 MiB | 20.87 MiB/s, done.\n",
            "Resolving deltas: 100% (1133/1133), done.\n",
            "/content/rectorch\n",
            "Requirement already satisfied: Bottleneck>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.3.2)\n",
            "Collecting munch>=2.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
            "Collecting pandas>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/11/e1f53db0614f2721027aab297c8afd2eaf58d33d566441a97ea454541c5e/pandas-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.6.0+cu101)\n",
            "Requirement already satisfied: cvxopt>=1.2.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.2.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.22.2.post1)\n",
            "Requirement already satisfied: hyperopt>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch>=2.5.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.2->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.2->-r requirements.txt (line 9)) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.2->-r requirements.txt (line 9)) (2.5)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.2->-r requirements.txt (line 9)) (3.11.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.2->-r requirements.txt (line 9)) (4.4.2)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 1.1.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: munch, pandas\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "Successfully installed munch-2.5.0 pandas-1.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNDNIOm8Fria"
      },
      "source": [
        "### Data loading and splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apYOn0PQjPHN"
      },
      "source": [
        "cfg_data = {\n",
        "    \"processing\": {\n",
        "        \"data_path\": \"../ml-1m/ratings.dat\",\n",
        "        \"threshold\": 3.5,\n",
        "        \"separator\": \"::\",\n",
        "        \"header\": None,\n",
        "        \"u_min\": 2,\n",
        "        \"i_min\": 0\n",
        "    },\n",
        "    \"splitting\": {\n",
        "        \"split_type\": \"vertical\",\n",
        "        \"sort_by\": None,\n",
        "        \"seed\": 98765,\n",
        "        \"shuffle\": True,\n",
        "        \"valid_size\": 100,\n",
        "        \"test_size\": 100,\n",
        "        \"test_prop\": 0.2\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME17EQJsnMpI",
        "outputId": "5ac45472-d773-4b61-ad35-6131d74e0c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from rectorch.data import DataProcessing\n",
        "dataset = DataProcessing(cfg_data).process_and_split()\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14:19:28-140920]  Reading raw data file ../ml-1m/ratings.dat.\n",
            "[14:19:32-140920]  NumExpr defaulting to 2 threads.\n",
            "[14:19:33-140920]  Thresholded 424928 ratings.\n",
            "[14:19:33-140920]  Applying filtering.\n",
            "[14:19:33-140920]  Filtered 1 ratings.\n",
            "[14:19:33-140920]  Shuffling data.\n",
            "[14:19:33-140920]  Calculating splits.\n",
            "[14:19:33-140920]  Creating validation and test set.\n",
            "[14:19:33-140920]  Skipped 2 ratings in validation set.\n",
            "[14:19:33-140920]  Skipped 3 ratings in test set.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(n_users=6037, n_items=3528, n_ratings=575275)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWI02RmBq2oB"
      },
      "source": [
        "For more details about how to load, process and splitting the dataset, please refer to the tutorial [rectorch_data_tutorial.ipynb](https://colab.research.google.com/drive/1gKgMllkYlvvBqh7q6WmmSvtfAOTz7tFh#scrollTo=Cwi1HjgJ-T7Z)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlE-Shq_AUgV"
      },
      "source": [
        "## Standard pipeline\n",
        "\n",
        "**rectorch** tries to make it the coders life easy by fixing a standard pipeline when it comes to training, and testing a recommender system.\n",
        "\n",
        "The pipeline follows this steps:\n",
        "\n",
        "* **Dataset creation**: seen above and in [this tutorial](https://colab.research.google.com/drive/1gKgMllkYlvvBqh7q6WmmSvtfAOTz7tFh#scrollTo=Cwi1HjgJ-T7Z);\n",
        "* **Sampler creation**: a sampler is an object that \"prepares\" the dataset for the recommender system. Some models can handle different data formats, while others require a specific sampler to work properly;\n",
        "* **Model initialization**: the creation of the model object with its own hyper-parameters;\n",
        "* **Training**: the training of the model which may need the sampler to handle the data;\n",
        "* **Evaluation**: the testing of the model that requires the sampler since it uses the `predict` method of the model to get the prediction that are compared with the ground truth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hfF9Lw-CDCx"
      },
      "source": [
        "### Sampler creation: rectorch.samplers\n",
        "\n",
        "A sampler is a convenient way to handle the dataset. It works like an interface between the dataset (which encapsulates a `pandas.Dataframe`) and the model. Standard samplers provided by **rectorch** handle different types of data or, in the case of neural model, they provide different ways of creating mini-batches.\n",
        "\n",
        "In the case of the baselines, we will use only the `rectorch.samplers.ArrayDummySampler` and `rectorch.samplers.SparseDummySampler`. The former handle the dataset as a `numpy.ndarray`, while the second as a `scipy.sparse.csr_matrix`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV-I2JwBESuB"
      },
      "source": [
        "from rectorch.samplers import ArrayDummySampler\n",
        "array_sampler = ArrayDummySampler(dataset, mode=\"train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG4l1O9kEZhT"
      },
      "source": [
        "The `mode` of a sampler indicates its current state, that is which part of the dataset is handling. In this case, the training set (\"train\") since we are going to train the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-6RlkWPrzYj"
      },
      "source": [
        "### Model initialization: Random recommender\n",
        "\n",
        "A random recommender is simply a system that recommends random items to users. The only useful parameter to initialize the model is the number of items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxah5DwWr6vZ"
      },
      "source": [
        "from rectorch.models.baseline import Random\n",
        "rnd = Random(dataset.n_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUWqBC_B_VrE"
      },
      "source": [
        "The training procedure is actually empty. However, for completeness lets call it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8c1P013SE9n"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVzi-BrV_HKJ"
      },
      "source": [
        "rnd.train(array_sampler) #useless call for this recommender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt_oO6EFFRPg"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Evaluating the performance of a model is really easy in **rectorch**. The simplest way is to call the `rectorch.evaluation.evaluate` function passing the model, the sampler and the list of metrics. To date, **rectorch** supports the following metrics:\n",
        "* hit@k\n",
        "* ndcg@k\n",
        "* recall@k\n",
        "* ap@k\n",
        "* mrr@k\n",
        "* auc\n",
        "\n",
        "When the metric has the parameter `k` it is automatically inferred from the provided string. Thus, giving \"ndcg@100\" is interpreted as `ndcg@k` with `k=100`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPEZr2XtFPsi"
      },
      "source": [
        "from rectorch.evaluation import evaluate\n",
        "array_sampler.test()\n",
        "results = evaluate(rnd, array_sampler, [\"ndcg@10\", \"recall@10\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYLs95AGGlX_"
      },
      "source": [
        "`results` is a dictionary where the keys are the tested metrics, and values (numpy arrays) are the scores for each user with that specific metric. Since usually it is convenient to compute the overall average of these values, **rectorch** provide a function (i.e.,`rectorch.utils.collect_results`) that does it. It returns, for each metric, the mean and stardard deviation as a pair of `float` values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkDcfXgFvmb",
        "outputId": "37cd6659-3cd9-43c8-895f-b8957b8f72ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from rectorch.utils import collect_results\n",
        "collect_results(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ndcg@10': (0.006845139397573328, 0.026022437770306373),\n",
              " 'recall@10': (0.0071111111111111115, 0.025940101944458293)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Om2xbFzHZi_"
      },
      "source": [
        "**NOTE**: before calling the `evaluate` function, we switched the sampler mode to `test`. This is a good practice since the evaluation can be also done in the validation set (not in the training!!). However, if the sampler is in `training` mode, when passed to the `evaluate` it will be automatically switched to `test` but a warning will appear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLSXkWV1Gj4V",
        "outputId": "4ad1c6d2-b6ed-48f1-89ae-6db769f71659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "array_sampler.train() #train mode to see the warning\n",
        "results = evaluate(pop, array_sampler, [\"ndcg@10\", \"recall@10\"])\n",
        "collect_results(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14:58:33-140920]  Sampler must be in valid or test mode. Froced switch to test mode!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ndcg@10': (0.09573019268352317, 0.11177790052280144),\n",
              " 'recall@10': (0.09690079365079365, 0.10916368351154157)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v5y_xARSdEK"
      },
      "source": [
        "## Other baseline models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eoi2agXBrc7M"
      },
      "source": [
        "### Popularity based recommender\n",
        "\n",
        "Popularity based recommender suggests the most popular items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyR_SRW7rb5U"
      },
      "source": [
        "from rectorch.models.baseline import Popularity\n",
        "pop = Popularity(dataset.n_items)\n",
        "pop.train(array_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3oPvhokGkFZ"
      },
      "source": [
        "array_sampler.test()\n",
        "results = evaluate(pop, array_sampler, [\"ndcg@10\", \"recall@10\"])\n",
        "collect_results(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szoxdd4zIIG8"
      },
      "source": [
        "### CF-KOMD\n",
        "\n",
        "CF-KOMD is a kernel-based method proposed by Polato et al. [[1](https://www.sciencedirect.com/science/article/abs/pii/S0925231218300900), [2](https://www.sciencedirect.com/science/article/abs/pii/S0925231217307592), [3](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2016-111.pdf)].\n",
        "The method is based on the concept of maximal margin (like in SVM) to compute the ranking between items. The optimization problem producing the ranking can be computed in parallel since for each user a different (and rather small) optimization problem is created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKKn2gJzH81O"
      },
      "source": [
        "from rectorch.models.baseline import CF_KOMD\n",
        "cfkomd = CF_KOMD(ker_fun=\"linear\", disj_degree=1, lam=0.1)\n",
        "cfkomd.train(array_sampler, only_test=True) #creates the model only for test users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVrmBa-eJG08",
        "outputId": "fc7d6a43-79d4-44c6-8333-5ff2e1b5c5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "array_sampler.test()\n",
        "results = evaluate(cfkomd, array_sampler, [\"ndcg@10\", \"recall@10\"])\n",
        "collect_results(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ndcg@10': (0.10585826119158127, 0.176156407032027),\n",
              " 'recall@10': (0.10102380952380952, 0.16248748599992546)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M21eWtUJvkC"
      },
      "source": [
        "### SLIM\n",
        "\n",
        "SLIM: Sparse Linear Methods for Top-N Recommender Systems.\n",
        "\n",
        "The SLIM [4](https://ieeexplore.ieee.org/document/6137254) model can be presented as\n",
        "$$\\tilde{\\mathbf{A}} = \\mathbf{A}\\mathbf{W}$$\n",
        "where $\\mathbf{A}$ is the rating matrix, $\\mathbf{W}$ is an $n \\times n$ sparse matrix of aggregation coefficients, and where each row of $\\tilde{\\mathbf{A}}$ represents the recommendation scores on all items for a user.\n",
        "\n",
        "The column of $\\mathbf{W}$ are learned independently by solving the following optimization problem:\n",
        "\n",
        "$$ \\operatorname{min}_{\\mathbf{w}_{j}} \\frac{1}{2} \\| \\mathbf{a}_{j} - A \\mathbf{w}_{j} \\|_{2}^{2} + \\frac{\\beta}{2} \\left\\| \\mathbf{w}_{j} \\right\\|_{2}^{2}+\\lambda \\left\\|\\mathbf{w}_{j}\\right\\|_{1} $$\n",
        "\n",
        "subject to\n",
        "$$\\mathbf{w}_{j} \\geq \\mathbf{0}, \\: w_{j, j}=0$$\n",
        "\n",
        "where ``l1_reg`` is $\\lambda$ and ``l2_reg`` is $\\beta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZKX4GWeJyHM"
      },
      "source": [
        "SLIM requires a different sampler because it handles sparse data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qokEpaQJMaS",
        "outputId": "65059a80-80d2-46cf-a4a0-4dc66ffcba2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from rectorch.models.baseline import SLIM\n",
        "from rectorch.samplers import SparseDummySampler\n",
        "\n",
        "sparse_sampler = SparseDummySampler(dataset, mode=\"train\")\n",
        "slim = SLIM(l1_reg=0.001, l2_reg=0.001)\n",
        "slim.train(sparse_sampler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15:15:28-140920]  | item 352/3528 | ms/user 23.86 |\n",
            "[15:15:36-140920]  | item 704/3528 | ms/user 22.76 |\n",
            "[15:15:43-140920]  | item 1056/3528 | ms/user 21.68 |\n",
            "[15:15:51-140920]  | item 1408/3528 | ms/user 20.51 |\n",
            "[15:15:57-140920]  | item 1760/3528 | ms/user 19.23 |\n",
            "[15:16:04-140920]  | item 2112/3528 | ms/user 18.80 |\n",
            "[15:16:10-140920]  | item 2464/3528 | ms/user 17.36 |\n",
            "[15:16:16-140920]  | item 2816/3528 | ms/user 15.15 |\n",
            "[15:16:20-140920]  | item 3168/3528 | ms/user 11.84 |\n",
            "[15:16:22-140920]  | item 3520/3528 | ms/user 6.69 |\n",
            "[15:16:22-140920]  | training complete | total training time 62.70 s |\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecYfsGl1L0W-",
        "outputId": "b29f92d7-47ac-4e68-f1c2-510a525d340f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sparse_sampler.test()\n",
        "results = evaluate(slim, sparse_sampler, [\"ndcg@10\", \"recall@10\"])\n",
        "collect_results(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ndcg@10': (0.32459041141786826, 0.24383642039019238),\n",
              " 'recall@10': (0.31967460317460317, 0.22155421976980716)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}