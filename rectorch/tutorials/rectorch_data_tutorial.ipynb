{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rectorch_data_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yYIlIpBVFB7"
      },
      "source": [
        "# **rectorch**: tutorial on data loading and processing\n",
        "\n",
        "This tutorial will show examples of how data can be loaded and processed using **rectorch**. Moreover, we will also explore the different possibilities offered by the library to handle the dataset splitting (i.e., training, validation and test set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIfa_IRJWIQV"
      },
      "source": [
        "## Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G-sq-6gVlKC"
      },
      "source": [
        "### Dataset download\n",
        "For the purposes of this tutorial we download the *movielens 1M* dataset. As the name suggests, this dataset contains roughly one million (5 stars) ratings about movies. For more details, please refer to the official web page https://grouplens.org/datasets/movielens/1m/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx-q130cT0QI",
        "outputId": "42ca8c1c-aea0-487e-ba6b-f1bd32c03c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "%cd /content/\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip\n",
        "!rm ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2020-09-13 19:35:09--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  6.70MB/s    in 0.8s    \n",
            "\n",
            "2020-09-13 19:35:10 (6.70 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izTnno0XlhLM"
      },
      "source": [
        "Let's have a look at the first lines of the dataset file..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aRX8Ih1lnQD",
        "outputId": "5c60e337-96e5-491f-d8ef-a7102f122bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head ./ml-1m/ratings.dat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1::1193::5::978300760\n",
            "1::661::3::978302109\n",
            "1::914::3::978301968\n",
            "1::3408::4::978300275\n",
            "1::2355::5::978824291\n",
            "1::1197::3::978302268\n",
            "1::1287::5::978302039\n",
            "1::2804::5::978300719\n",
            "1::594::4::978302268\n",
            "1::919::4::978301368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abCB7-vElx0G"
      },
      "source": [
        "The format is: `user_id`::`item_id`::`rating`::`timestamp`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0kfGGSYWKXU"
      },
      "source": [
        "### **rectorch** installation\n",
        "\n",
        "NOTE: in this version of the tutorial we load the *dev* version from [github](https://github.com/makgyver/rectorch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryMvRCKwT6mv",
        "outputId": "4d44222c-8574-4ab9-da8c-528d94c73fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "%cd /content/\n",
        "!git clone -b dev https://github.com/makgyver/rectorch.git\n",
        "%cd rectorch\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'rectorch'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 1698 (delta 11), reused 30 (delta 11), pack-reused 1650\u001b[K\n",
            "Receiving objects: 100% (1698/1698), 3.22 MiB | 5.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1127/1127), done.\n",
            "/content/rectorch\n",
            "Requirement already satisfied: Bottleneck>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.3.2)\n",
            "Collecting munch>=2.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
            "Collecting pandas>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/11/e1f53db0614f2721027aab297c8afd2eaf58d33d566441a97ea454541c5e/pandas-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5MB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.6.0+cu101)\n",
            "Requirement already satisfied: cvxopt>=1.2.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.2.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.22.2.post1)\n",
            "Requirement already satisfied: hyperopt>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch>=2.5.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.2->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.2->-r requirements.txt (line 9)) (2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.2->-r requirements.txt (line 9)) (4.41.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.2->-r requirements.txt (line 9)) (3.11.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.2->-r requirements.txt (line 9)) (4.4.2)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 1.1.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: munch, pandas\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "Successfully installed munch-2.5.0 pandas-1.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH3_cFmzUn_M"
      },
      "source": [
        "**WARNING: for compatibility issue with `pandas`, the runtime must be restarted after running the previous cells!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEH4hq2lk-cj",
        "outputId": "8b5260b4-65db-4a3d-a260-471e65733241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd rectorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rectorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNDNIOm8Fria"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tTL8ezXFuDe"
      },
      "source": [
        "To load and process the dataset using **rectorch**, it is necessary to define the data configuration dictionary (or JSON file). The configuration must contain all the information for reading, processing and splitting the dataset.\n",
        "\n",
        "The structure of this configuration dictionary is the following:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"processing\" : {\n",
        "        \"data_path\" : [str] the path where the dataset (csv) file is stored,\n",
        "        \"threshold\" : [float] the (minimal) threshold to apply to the ratings to binarize them (0 if no threshold),\n",
        "        \"separator\" : [str] the columns separator used in the csv file,\n",
        "        \"header\" : [int] the header line/s (None if not present),\n",
        "        \"u_min\" : [int] the minimum number of ratings that a user must have to be taken,\n",
        "        \"i_min\" : [int] the minimum number of ratings that an item must have to be taken\n",
        "    },\n",
        "    \"splitting\" : {\n",
        "        \"split_type\" : [str] 'vertical'/'horizontal' depending on the needs,\n",
        "        \"sort_by\" : [str] the column used to sort the ratings (None if no ordering required),\n",
        "        \"seed\" : [int] random seed,\n",
        "        \"shuffle\" : [bool] whether the ratings must be shuffled before splitting,\n",
        "        \"valid_size\" : [int,float] number of users or proportion of users/ratings to be held for validation,\n",
        "        \"test_size\" : [int,float] number of users or proportion of users/ratings to be held for test,\n",
        "        \"test_prop\" : [float] proportion of ratings used in the test (used only in case of vertical splitting)\n",
        "        \"cv\" : [int] number of times this splitting has to be repeated. If omitted only one splitting will be performed.\n",
        "    }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjePXRmJW_gv"
      },
      "source": [
        "In the following example the dataset (i.e., `ml-1m`) is processed as follows:\n",
        "\n",
        "* ratings are binarized according to the threshold rating 3.5, i.e., if $r_{ui} > 3.5$ than it is considered as a positive feedback, otherwise a negative feedback;\n",
        "* users with less than 2 ratings are discarded;\n",
        "* items with less than 1 ratings are discarded;\n",
        "\n",
        "Then, it is splitted as follows:\n",
        "\n",
        "* vertically, i.e., users that appear in the validation/test set are not included in the training;\n",
        "* the validation set contains 100 users;\n",
        "* the test set contains 100 users;\n",
        "* both the test and the validation set consider 80% of the users' reatings as the \"training part\" of the users and the rest as \"test part\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apYOn0PQjPHN"
      },
      "source": [
        "cfg_data = {\n",
        "    \"processing\": {\n",
        "        \"data_path\": \"../ml-1m/ratings.dat\",\n",
        "        \"threshold\": 3.5,\n",
        "        \"separator\": \"::\",\n",
        "        \"header\": None,\n",
        "        \"u_min\": 2,\n",
        "        \"i_min\": 0\n",
        "    },\n",
        "    \"splitting\": {\n",
        "        \"split_type\": \"vertical\",\n",
        "        \"sort_by\": None,\n",
        "        \"seed\": 98765,\n",
        "        \"shuffle\": True,\n",
        "        \"valid_size\": 100,\n",
        "        \"test_size\": 100,\n",
        "        \"test_prop\": 0.2\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z6eqdalHnzJ"
      },
      "source": [
        "### Horizontal vs. Vertical split\n",
        "\n",
        "Splitting (training-test) a recommendation dataset can be done in mainly two ways. Given a dataset **D** (e.g., read from a csv file):\n",
        "\n",
        "* **[Horizontal]** X% of the ratings are randomly taken from **D** to form the training set, and the rest (100-X)% for the test set. This is called *horizontal* splitting because, if we think of the rating matrix **R** (users on the rows), we are taking part of the rows as training and the rest as test.\n",
        "\n",
        "* **[Vertical]** A fixed set of users is kept for training and the remaining for test. This is called *vertical* splitting because we are vertically cutting the rating matrix in two parts. However, for the test users, part of their ratings (1-test_prop) can be used as \"known\" ratings (to avoid cold-start).\n",
        "\n",
        "Clearly, the same concept applies in the case of training-validation-test split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHrxj4Npoe5u"
      },
      "source": [
        "### Using/Starting from default configurations\n",
        "\n",
        "**rectorch** offers some default configurations to start with. For example, to get the standard configuration for the *movielens 1M* dataset use the `get_data_cfg` from the `rectorch.utils` module passing the `\"ml1m\"` as parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "089sswNRo0IX",
        "outputId": "6488aea5-e92d-468c-9f68-4d8022a3ae77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from rectorch.utils import get_data_cfg\n",
        "cfg = get_data_cfg(\"ml1m\")\n",
        "cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'processing': {'data_path': './ml-1m/ratings.dat',\n",
              "  'header': None,\n",
              "  'i_min': 0,\n",
              "  'separator': '::',\n",
              "  'threshold': 3.5,\n",
              "  'u_min': 5},\n",
              " 'splitting': {'seed': 98765,\n",
              "  'shuffle': 1,\n",
              "  'sort_by': None,\n",
              "  'split_type': 'vertical',\n",
              "  'test_prop': 0.2,\n",
              "  'test_size': 750,\n",
              "  'valid_size': 750}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn107mPppEvW"
      },
      "source": [
        "The default configurations can be used \"as is\", or they can be used as a starting point (dataset specific settings are already correct!) to define different configurations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCrvCXX0bQ4Q"
      },
      "source": [
        "## Creating the dataset\n",
        "\n",
        "Once the configuration is ready, the dataset creation is simply performed using the `rectorch.data.DataProcessing` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME17EQJsnMpI",
        "outputId": "7f7bb644-f3cd-41cf-d543-3c42ccc9ba96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from rectorch.data import DataProcessing\n",
        "dataset = DataProcessing(cfg_data).process_and_split()\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19:36:02-130920]  Reading raw data file ../ml-1m/ratings.dat.\n",
            "[19:36:06-130920]  NumExpr defaulting to 2 threads.\n",
            "[19:36:06-130920]  Thresholded 424928 ratings.\n",
            "[19:36:06-130920]  Applying filtering.\n",
            "[19:36:06-130920]  Filtered 1 ratings.\n",
            "[19:36:06-130920]  Shuffling data.\n",
            "[19:36:06-130920]  Calculating splits.\n",
            "[19:36:06-130920]  Creating validation and test set.\n",
            "[19:36:06-130920]  Skipped 2 ratings in validation set.\n",
            "[19:36:06-130920]  Skipped 3 ratings in test set.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(n_users=6037, n_items=3528, n_ratings=575275)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxc2gzJ3sgce"
      },
      "source": [
        "General information about the dataset can be retrieved using its own attributes, e.g., "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zClFrAm5smj3"
      },
      "source": [
        "print(\"# of users: %d\" %dataset.n_user)\n",
        "print(\"# of items: %d\" %dataset.n_items)\n",
        "print(\"# of ratings: %d\" %dataset.n_ratings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfyuyvtab85Y"
      },
      "source": [
        "Training, validation and test set are contained (in form of `pandas.DataFrame`) inside the `dataset` object and they can be easily retrieved using the attributes `train_set`, `valid_set` or `test_set`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wWAhy7YbjWC",
        "outputId": "367ab739-bf35-4081-b98c-60360800566a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# The training set\n",
        "dataset.train_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>iid</th>\n",
              "      <th>rating</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1103</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1103</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1103</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1103</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>978302039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1103</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>978300719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000202</th>\n",
              "      <td>3149</td>\n",
              "      <td>188</td>\n",
              "      <td>4</td>\n",
              "      <td>956704996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000205</th>\n",
              "      <td>3149</td>\n",
              "      <td>741</td>\n",
              "      <td>5</td>\n",
              "      <td>956704887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000206</th>\n",
              "      <td>3149</td>\n",
              "      <td>203</td>\n",
              "      <td>5</td>\n",
              "      <td>956704746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000207</th>\n",
              "      <td>3149</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>956715648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000208</th>\n",
              "      <td>3149</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>956715569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>555607 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          uid  iid  rating          3\n",
              "0        1103    0       5  978300760\n",
              "3        1103    1       4  978300275\n",
              "4        1103    2       5  978824291\n",
              "6        1103    3       5  978302039\n",
              "7        1103    4       5  978300719\n",
              "...       ...  ...     ...        ...\n",
              "1000202  3149  188       4  956704996\n",
              "1000205  3149  741       5  956704887\n",
              "1000206  3149  203       5  956704746\n",
              "1000207  3149  100       4  956715648\n",
              "1000208  3149   19       4  956715569\n",
              "\n",
              "[555607 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGQkYO7m-UUR"
      },
      "source": [
        "Being the dataset vertically splitted, both the validation and test set are composed of two parts (know|unknown ratings as explained above). For this reason, `valid_test` and `test_test` will return a pair (`list`) of Dataframes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwi1HjgJ-T7Z",
        "outputId": "696c5101-816e-4267-9a71-2c67a23e0042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "dataset.test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[         uid  iid  rating          3\n",
              " 233     5971   51       5  978294008\n",
              " 236     5971  493       4  978294260\n",
              " 238     5971   36       5  978294199\n",
              " 240     5971   77       4  978294008\n",
              " 242     5971   86       5  978294199\n",
              " ...      ...  ...     ...        ...\n",
              " 996816  5953  983       4  956763510\n",
              " 996818  5953  577       5  956763317\n",
              " 996820  5953  827       4  956763657\n",
              " 996821  5953  615       4  956763639\n",
              " 996824  5953   30       5  956763445\n",
              " \n",
              " [8043 rows x 4 columns],          uid   iid  rating          3\n",
              " 235     5971   733       4  978294282\n",
              " 237     5971   764       4  978294282\n",
              " 239     5971    40       5  978294230\n",
              " 13348   5985   579       4  977546807\n",
              " 13354   5985  1118       4  977546875\n",
              " ...      ...   ...     ...        ...\n",
              " 988561  5976   580       5  956975355\n",
              " 988563  5976  1120       5  956975467\n",
              " 996793  5953   190       4  956763473\n",
              " 996794  5953  1761       5  956763510\n",
              " 996796  5953   729       4  956763318\n",
              " \n",
              " [1961 rows x 4 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk8YmiBdcfbq"
      },
      "source": [
        "The `Dataset` class also offers methods for converting the dataset into different standard formats. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JNRgIyLcpIf",
        "outputId": "796a7ab1-4c77-4207-8344-303f55d329f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "array_tr, array_val, array_te = dataset.to_array()\n",
        "array_tr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-jxi_D5c0O5"
      },
      "source": [
        "`Dataset.to_array()` converts the dataset to `numpy.ndarray`.\n",
        "\n",
        "Similarly:\n",
        "* `to_sparse()` converts to `scipy.sparse.csr_matrix`;\n",
        "* `to_tensor()` converts to `torch.FloatTensor`;\n",
        "* `to_dict()` converts to `dict` with users as keys and list of items as values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IKmVYD8rZBL"
      },
      "source": [
        "### Save/load the dataset to/from file\n",
        "\n",
        "Once the dataset is created, it can be saved to file(s) for later usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQSzlsourqAf",
        "outputId": "b266ffd5-05d5-453e-a22a-41eb9da7737e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "dataset.save(\"ml-1m/processed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19:36:12-130920]  Saving unique_iid.txt.\n",
            "[19:36:12-130920]  Saving unique_uid.txt.\n",
            "[19:36:12-130920]  Saving all the files.\n",
            "[19:36:13-130920]  Dataset saved successfully!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT99tWuXrxYk"
      },
      "source": [
        "The loading is as easy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMPMt3TKrw70"
      },
      "source": [
        "from rectorch.data import Dataset\n",
        "dataset2 = Dataset.load(\"ml-1m/processed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dFR-lXxs3bG"
      },
      "source": [
        "Let's check if the two datasets are actually the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOBZvr6_sG68",
        "outputId": "8abec3b5-4274-440b-c1b1-7e719f24a710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "print(np.all(dataset.train_set.values    == dataset2.train_set.values) &\n",
        "      np.all(dataset.valid_set[0].values == dataset2.valid_set[0].values) &\n",
        "      np.all(dataset.valid_set[1].values == dataset2.valid_set[1].values) &\n",
        "      np.all(dataset.test_set[0].values  == dataset2.test_set[0].values) &\n",
        "      np.all(dataset.test_set[1].values  == dataset2.test_set[1].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fDBXRRvEoju"
      },
      "source": [
        "Yes, they are!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cmoGSVajy8k"
      },
      "source": [
        "## ... and much more\n",
        "\n",
        "More details about the `rectorch.data` module can be retrieved from the [official documention](https://makgyver.github.io/rectorch/data.html)."
      ]
    }
  ]
}